{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import mm3dtestdata as mm3d\n",
    "import fusecam\n",
    "from fusecam.geometric import space\n",
    "from fusecam.geometric import embedplane\n",
    "from fusecam.geometric import interpolate\n",
    "from fusecam.manipimg import rotate_tensor_cube\n",
    "\n",
    "from fusecam.aiutil import train_scripts\n",
    "from fusecam.aiutil import ensembling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from dlsia.core.networks import sms3d\n",
    "from dlsia.core import helpers\n",
    "from dlsia.viz_tools import draw_sparse_network\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-ordinary",
   "metadata": {},
   "source": [
    "First we need to build test data, low res and high res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 64\n",
    "border = 10\n",
    "radius = 10\n",
    "\n",
    "sigma_low = 3.0\n",
    "sigma_high = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = mm3d.balls_and_eggs(scale=scale, border=border, radius=radius, k0=1.0)\n",
    "_, instance_map_0, class_map_0 = obj.fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('Set1', 3)\n",
    "plt.imshow(class_map_0[32,...], cmap=cmap, interpolation='none')\n",
    "cbar = plt.colorbar(ticks=[0,1,2,3] )#np.arange(np.min(0), np.max(3) + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_low = mm3d.blur_it(class_map_0, sigma=sigma_low)\n",
    "class_map_high = mm3d.blur_it(class_map_0, sigma=sigma_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo_class_0 = np.array([0])\n",
    "tomo_class_1 = np.array([0.05])\n",
    "tomo_class_2 = np.array([0.25])\n",
    "tomo_class_3 = np.array([0.35])\n",
    "class_actions_tomo = np.column_stack([tomo_class_0,\n",
    "                                      tomo_class_1,\n",
    "                                      tomo_class_2,\n",
    "                                      tomo_class_3]).T\n",
    "\n",
    "plt.bar( [\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"],class_actions_tomo.ravel() )\n",
    "plt.title(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_map = mm3d.compute_weighted_map(class_map_low, class_actions_tomo)\n",
    "high_map = mm3d.compute_weighted_map(class_map_high, class_actions_tomo)\n",
    "\n",
    "low_map = low_map + mm3d.noise(low_map, 0.01, 0.0)\n",
    "high_map = high_map + mm3d.noise(high_map, 0.01, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(low_map[0, :,:,scale//2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(high_map[0, :,:,scale//2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-disposition",
   "metadata": {},
   "source": [
    "Now that we have data, I will use have to make the geometric objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_object = space.SpatialVolumeMetric(origin=(0,0,0),\n",
    "                                         step_size=(1,1,1),\n",
    "                                         orientation = torch.eye(3),\n",
    "                                         translation = (0,0,0),\n",
    "                                        )\n",
    "plane_object = space.SpatialPlaneMetric(origin=(0,0),\n",
    "                                         step_size=(1,1),\n",
    "                                         orientation = torch.eye(2),\n",
    "                                         translation = (0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-techno",
   "metadata": {},
   "source": [
    "Now we have the two geometric objects, I want define a plane and get stuff going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.linspace(0,scale-1,scale)\n",
    "U,V = torch.meshgrid(u,u, indexing='ij')\n",
    "UV = torch.concat([U.flatten().reshape(1,-1), V.flatten().reshape(1,-1)]).T\n",
    "\n",
    "x = torch.linspace(0,scale-1,scale)\n",
    "X,Y,Z = torch.meshgrid(x,x,x, indexing=\"ij\")\n",
    "XYZ = torch.concat([X.flatten().reshape(1,-1), Y.flatten().reshape(1,-1), Z.flatten().reshape(1,-1),]).T \n",
    "print(UV.shape, XYZ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner_1 = embedplane.Plane3DAligner(\n",
    "    normal=[0.0, 0.00, 1.0], \n",
    "    point_on_plane=[scale//2, scale//2, scale//2]\n",
    ")\n",
    "point_on_plane_2D_1 = (scale//2,scale//2)\n",
    "aligned_points_1 = aligner_1.align_points_to_3d(UV, point_on_plane_2D_1, rotation_angle=0)\n",
    "\n",
    "aligner_2 = embedplane.Plane3DAligner(\n",
    "    normal=[0.0, -1.0, 0.0], \n",
    "    point_on_plane=[scale//2, scale//2, scale//2]\n",
    ")\n",
    "point_on_plane_2D_2 = (scale//2,scale//2)\n",
    "aligned_points_2 = aligner_2.align_points_to_3d(UV, point_on_plane_2D_2, rotation_angle=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_1, near_dist_1 = interpolate.find_nearest(XYZ, aligned_points_1, 5)\n",
    "weights_1 = interpolate.compute_weights(near_dist_1, power=3.0, cutoff=2.0)\n",
    "\n",
    "indices_2, near_dist_2 = interpolate.find_nearest(XYZ, aligned_points_2, 5)\n",
    "weights_2 = interpolate.compute_weights(near_dist_2, power=3.0, cutoff=2.0)\n",
    "\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "funct_1 = interpolate.inverse_distance_weighting_with_weights(torch.Tensor(high_map.flatten()), \n",
    "                                                                         indices_1, \n",
    "                                                                         weights_1)\n",
    "funct_2 = interpolate.inverse_distance_weighting_with_weights(torch.Tensor(high_map.flatten()), \n",
    "                                                                         indices_2, \n",
    "                                                                         weights_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "funct_1= einops.rearrange(funct_1, \"(X Y) -> X Y \",X=scale, Y=scale)\n",
    "plt.imshow(funct_1.numpy() )\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(high_map[0, :,:,scale//2])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "funct_2 = einops.rearrange(funct_2, \"(X Y) -> X Y\",X=scale, Y=scale)\n",
    "plt.imshow(funct_2.numpy() )\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow( high_map[0, :,scale//2,:]) \n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(funct_1.numpy() - high_map[0, :,:,scale//2])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(funct_2.numpy() - high_map[0, :,scale//2,:])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-percentage",
   "metadata": {},
   "source": [
    "Build Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_3d_maps = torch.concat([torch.Tensor(low_map).unsqueeze(0),\n",
    "                           torch.Tensor(low_map).unsqueeze(0)])\n",
    "my_2d_maps = torch.concat([torch.Tensor(high_map[0, :,:,32]).flatten().unsqueeze(0),\n",
    "                           torch.Tensor(high_map[0, :,32,:]).flatten().unsqueeze(0)])\n",
    "my_weights = torch.concat([weights_1.unsqueeze(0), weights_2.unsqueeze(0) ])\n",
    "my_indices = torch.concat([indices_1.unsqueeze(0), indices_2.unsqueeze(0)])\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = TensorDataset(my_3d_maps, my_2d_maps, my_weights, my_indices)                          \n",
    "data_loader = DataLoader(my_data, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_networks = 7\n",
    "networks = ensembling.construct_3dsms_ensembler(n_networks=n_networks,\n",
    "                                                in_channels=1,\n",
    "                                                out_channels=1,\n",
    "                                                layers = 20,\n",
    "                                                alpha=0.00,\n",
    "                                                gamma=0.00,\n",
    "                                                hidden_channels=[5],\n",
    "                                                parameter_bounds=[80000,90000]\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-occupation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for net in networks:\n",
    "    print( helpers.count_parameters(net) )\n",
    "    a,b,c = draw_sparse_network.draw_network(net)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in networks:\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0051\n",
    "    train_scripts.train_volume_on_slice()net, \n",
    "            loss_function, \n",
    "            optimizer, \n",
    "            data_loader, \n",
    "            500, \n",
    "            interpolate.inverse_distance_weighting_with_weights, device='cpu'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, loss_function, optimizer, dataloader, num_epochs, interpolate_function, device='cuda:0'):\n",
    "    net.to(device)  # Move the network to the specified device\n",
    "    net.train()  # Set the network to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            img_tensor_3d, flat_2d_tensor, weights, indices = [item.to(device) for item in batch]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(img_tensor_3d)\n",
    "            loss = 0.0\n",
    "            for img3d, img2d, ws, idx in zip(outputs, flat_2d_tensor, weights, indices):\n",
    "                img_flat = img3d.flatten()\n",
    "                interp = interpolate_function(img_flat, idx, ws)\n",
    "                not_nan_sel = ~torch.isnan(interp)\n",
    "\n",
    "                # Compute loss\n",
    "                loss += loss_function(interp[not_nan_sel], img2d[not_nan_sel])\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-neutral",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an L1 loss function\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0051)  # You can adjust the learning rate as needed\n",
    "train_model(net, \n",
    "            loss_function, \n",
    "            optimizer, \n",
    "            data_loader, \n",
    "            500, \n",
    "            interpolate.inverse_distance_weighting_with_weights, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tmp3 = net.cpu()(torch.Tensor(low_map).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (tmp1+tmp2+tmp3)/3.0\n",
    "s = torch.sqrt((tmp1**2+tmp2**2+tmp3**2)/3.0 - m*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "v = napari.view_image(low_map)\n",
    "v.add_image(m.numpy()[0])\n",
    "v.add_image(s.numpy()[0])\n",
    "v.add_image(high_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m.numpy()[0, 0,:,:,scale//2-15])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(high_map[0,:,:,scale//2-15])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(low_map[0,:,:,scale//2-15])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-phoenix",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsia-new",
   "language": "python",
   "name": "dlsia-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
